# 系統功能規格文件 (v2)

**版本：** 2.0.0
**更新日期：** 2025-03-15

## 1. 簡介

本系統是一套內部專用的資源調度與管理平台，提供下列能力：
1. **資源管理**：管理實體機（Baremetal）、虛擬機（VirtualMachine）、Kubernetes 叢集（K8sCluster）及相關網路與周邊資源。
2. **維護管理**：可指派「個人維護者 (Maintainer)」或「維護者群組 (MaintainerGroup)」負責管理各種資源，並掌握資源所有者或維護者。
3. **多維度分組**：支援「機架 (Rack)」與「實體機群組 (BaremetalGroup)」的概念，可依據地理位置、負載狀況等不同條件，將實體機進行彈性分組。
4. **租戶與配額**：可為不同租戶 (Tenant) 設定在某一資源群組內的配額限制（CPU、記憶體、儲存空間等）。
5. **K8s 叢集管理**：提供 Kubernetes 叢集的建立與管理，包括外掛 (Plugins)、Service Mesh、與堡壘機 (Bastion) 之關聯設定。
6. **自動化調度**：在建立虛擬機或叢集資源時，系統會根據租戶配額、群組可用量、實體機可用量等進行自動化調度與分配。

本文件將以功能面為主進行描述，**不**包含詳細的資料表結構說明；有關資料庫之設計與各表欄位，可參考獨立的資料庫設計文件 (v2.0.0)。

---

## 2. 系統定位與目標

1. **資源維運可視化**：提供對實體機、虛擬機、K8s 叢集等資源的即時掌握，包括其狀態、位置、已用/可用容量等。
2. **角色分工清晰**：可為每個資源指派個人或群組維護者，以利維運責任劃分與後續稽核。
3. **多租戶環境**：支援將整個資料中心切分給不同組織/部門 (Tenant) 使用，各租戶有可獨立控管的資源配額。
4. **自動化調度機制**：依據資源剩餘量、群組負載、租戶配額等條件，挑選出最適合的實體機或群組，以快速響應建立虛擬機 / 叢集的需求。
5. **K8s 全貌管理**：提供 Kubernetes 叢集層級的監控、外掛管理、堡壘機串接與 Service Mesh 管理等功能。
6. **彈性擴充**：可藉由外掛與多型態關聯 (Polymorphic Association) 機制，拓展系統支持的資源或功能模組。

---

## 3. 系統主要功能

以下按照系統核心邏輯與業務需求，說明主要功能模組與其行為。

### 3.1 維護者 (Maintainer) 與維護者群組 (MaintainerGroup)

- **維護者 (Maintainer)**
  - 記錄維運人員的基本資訊（姓名、帳號、聯絡方式等）。
  - 系統內的「維運責任歸屬」可以指派給單一維護者。

- **維護者群組 (MaintainerGroup)**
  - 將多位維護者歸為一個群組，利於大型專案或團隊共同維運。
  - 具備群組管理者 (group_manager) 機制，用於設定該群組的主要負責人。
  - 可透過多對多關聯（MaintainerToMaintainerGroup）讓維護者隨時加入或退出群組。

- **資源與維護者的多型關聯 (ResourceMaintainer)**
  - 系統內幾乎所有資源（例如 Baremetal、VirtualMachine、K8sCluster 等）都能透過此機制指派給維護者 (個人) 或維護者群組。
  - 支援在同一個資源上設置多位維運人員或群組，對於具高複雜度的環境維運特別有用。

> **使用情境範例**：  
> - 某租戶的 K8s 叢集故障，需要找群組 A 來排查；此時，在 `ResourceMaintainer` 中就能查到該叢集的維運群組是 A，並得知其管理者與成員名單。

---

### 3.2 實體機 (Baremetal) 與機架 (Rack) 管理

- **機架 (Rack)**
  - 針對實體機在資料中心中的實際位置，記錄機架名稱、BGP/AS 編號等網路相關資訊。
  - 有助於大型資料中心中快速定位問題機架或進行網路配置調度。

- **實體機 (Baremetal)**
  - 替代舊版系統的 Host，詳細記錄機器名稱、序號、可用資源 (CPU/記憶體/儲存空間) 以及所屬的機架 (Rack) 與群組 (BaremetalGroup)。
  - 可追蹤實體機歸屬的資料中心區域 (region)、機房 (dc)、機櫃位置 (rack & unit) 等資訊，用於跨區部署與運維。

- **實體機群組 (BaremetalGroup)**
  - 依不同維度（例如地理位置或負載）彈性地將多台實體機歸在同一群組。
  - 在系統中，租戶配額通常是以群組維度在做管控。

> **使用情境範例**：  
> - 要對特定機櫃進行網路升級，可以透過 `Rack` 快速篩選出位於該機櫃的所有實體機；再進一步檢視這些實體機所承載的業務影響範圍。

---

### 3.3 租戶 (Tenant) 與配額 (BaremetalGroupTenantQuota)

- **租戶 (Tenant)**
  - 代表系統使用者或部門，系統將針對每個租戶設定不同層級的資源使用權限。
  - 可以同時在多個 `BaremetalGroup` 拥有配額。

- **配額 (BaremetalGroupTenantQuota)**
  - 針對「某租戶在某個實體機群組」的可用資源上限或分配量做紀錄與控管。
  - 支援設定 CPU、記憶體、儲存空間的上限，或者使用百分比 (quota percentage) 的形式，靈活應對不同租戶需求。

> **使用情境範例**：  
> - 租戶 A 在「群組 X」擁有 50% 的 CPU 資源及 500 GB 儲存空間上限，若超過該配額，系統將無法再該群組內為租戶 A 建立更多虛擬機。

---

### 3.4 虛擬機 (VirtualMachine) 與規格 (VirtualMachineSpecification)

- **虛擬機規格 (VirtualMachineSpecification)**
  - 預先定義常用的 VM 規格 (CPU、記憶體、儲存空間)；可附帶版本或世代編號 (generation) 以利版本區分。
  - 建立新 VM 時可直接選取某個規格，系統將據此分配所需實體資源。

- **虛擬機 (VirtualMachine)**
  - 每個 VM 均有所屬的租戶 (Tenant)、部署在哪台實體機 (Baremetal)、使用哪種規格 (VirtualMachineSpecification) 等。
  - 可進一步標註該 VM 是否隸屬於某個 K8s 叢集，並指定 VM 的角色 (control-plane、worker、management 等)。

> **使用情境範例**：  
> - 系統收到「建立 4C8G VM」的需求，對應到 `VirtualMachineSpecification` 裏名為 "Standard-4C8G" 的條目，經配額及調度演算法後，挑選出實體機 X 部署新 VM，最後在 `VirtualMachine` 表中留存建置紀錄。

---

### 3.5 Kubernetes 叢集 (K8sCluster) 與週邊管理

#### 3.5.1 K8sCluster

- 紀錄 K8s 叢集的核心資訊，例如叢集名稱、版本、所屬租戶、狀態 (active / maintenance / offline / error) 等。
- 與 VM 關聯：在叢集建立過程中，通常需要多台虛擬機做控制平面 (control-plane) 與工作節點 (worker)；系統會將這些 VM 標註為隸屬某 K8sCluster。

#### 3.5.2 K8sClusterPlugin

- 系統可安裝各種外掛 (Plugins) 到 Kubernetes 叢集上，如網路外掛、監控外掛、儲存外掛等。
- 能記錄外掛的名稱、版本、狀態 (active/inactive/error)；在管理多叢集且不同外掛版本時尤其重要。

#### 3.5.3 BastionClusterAssociation

- 針對有堡壘機 (Bastion) 的場景，系統提供此關聯來紀錄「哪台 VM」作為某叢集的堡壘機。
- 方便在多個叢集都使用同一台堡壘機（或不同堡壘機）的時候，能快速查詢與管理。

#### 3.5.4 ServiceMesh 與 K8sClusterToServiceMesh

- **ServiceMesh**：定義了 Service Mesh 本身的名稱、類型 (cilium / istio / other)、版本與狀態等資訊。
- **K8sClusterToServiceMesh**：將特定的 K8s 叢集綁定到特定 Service Mesh，並可指派該 Mesh 在叢集中的角色 (primary / secondary)。
- 使得系統能支援多叢集下的 Service Mesh 部署策略，或同時運行多種 Service Mesh 用於測試比較。

> **使用情境範例**：  
> - 系統在租戶 B 的 K8s 叢集上安裝 Istio 作為 Service Mesh，並於 `K8sClusterToServiceMesh` 產生對應關聯紀錄，以便在故障排查時能清楚地知道該叢集使用的是哪個版本的 Istio。

---

## 4. 自動化資源調度

### 4.1 調度目標

- **租戶配額檢查**：當要建立虛擬機或 K8s 叢集時，先檢查對應租戶在指定群組的配額。
- **群組可用資源**：檢查該群組內所有實體機的可用 CPU、記憶體及儲存空間等，找出符合需求且負載最適合的實體機。
- **地理或機櫃條件**（選用）：可以在調度演算法中納入 `Rack`、`region`、`dc` 等屬性，執行更精細的調度。

### 4.2 調度流程

1. **收到建立/擴增需求**  
   - 使用者透過 API 提出建立虛擬機 (VM) 或 K8s 叢集的請求，需指定：
     - 租戶 (Tenant)  
     - 目標群組 (BaremetalGroup)  
     - VM 規格 (若為單純建立 VM) 或叢集版本/外掛 (若為建立 K8s 叢集)  
2. **檢查配額與資源**  
   - 由系統查詢 `BaremetalGroupTenantQuota`，判斷租戶在該群組是否還有足夠配額。  
   - 進一步檢索此群組下所有 `Baremetal` 狀態，篩選出可容納需求規格的實體機清單。  
3. **選擇最適合實體機**  
   - 系統可實作多種策略（例如最小剩餘空間優先、或最大剩餘空間優先等）來找出最合適的 Baremetal。  
4. **分配與建立**  
   - 若找到合適的實體機，系統在資料庫中建立對應的 `VirtualMachine` 或更新對應的 `K8sCluster` 紀錄，並透過外部的 Provision Agent/工具實際執行部署。  
   - 資源使用量同時更新（該實體機與該群組的 available_cpu / memory / storage 皆扣減）。  
5. **回報結果**  
   - 若部署成功，系統回傳成功訊息並更新狀態為 `active`；若調度失敗（無可用資源），系統回報錯誤，提示使用者更換群組或調整需求。

---

## 5. 典型使用情境與功能示例

### 5.1 新增與管理維護者

1. **新增個人維護者 (Maintainer)**：管理者在後台輸入該員工姓名、帳號、狀態等，建立一筆維護者紀錄。  
2. **建立維護者群組 (MaintainerGroup)**：設定群組名稱、群組管理者；將若干個維護者 (Maintainer) 加入群組。  
3. **指派資源維運**：在「ResourceMaintainer」中將某台實體機 (Baremetal) 或某個 K8s 叢集指派給個別維護者或維護者群組，後續有任何變動都能追蹤。

### 5.2 建立實體機並指定機架

1. **新增機架 (Rack)**：可預先於系統中創建機架資訊，填寫機架名稱、BGP/AS 編號或任何網路相關資訊。  
2. **建立實體機 (Baremetal)**：系統記錄該機器位於哪個機架、可用資源、序號等；將其歸屬至某個實體機群組 (BaremetalGroup) 中。  
3. **查詢機架資源**：運維人員可在控制介面選擇某個機架以檢視該機架所有實體機的運行狀況及負載統計。

### 5.3 租戶配額設定

1. **建立租戶 (Tenant)**：為某組或部門開通租戶帳號，設定名稱與說明。  
2. **設定群組配額 (BaremetalGroupTenantQuota)**：可對該租戶在特定實體機群組內設定 CPU 百分比、記憶體上限與儲存空間上限。  
3. **動態調整**：若該租戶發展擴大，需要更多配額，可隨時調整數值，並於後台管理介面紀錄更新時間。

### 5.4 建立虛擬機

1. **使用者提交 VM 建立請求**：包含規格 (VirtualMachineSpecification)、目標租戶、目標群組等資訊。  
2. **系統檢查**：系統先檢查租戶在該群組的可用配額，並找到符合需求規格且資源足夠的實體機 (Baremetal)。  
3. **預留並部署**：系統預留資源後透過外部 Provision Agent 建立 VM，若成功則更新 `VirtualMachine` 狀態為 `active`。  
4. **維運指派**：可在 `ResourceMaintainer` 中將此 VM 指派給某位維護者以利後續管理。

### 5.5 建立 Kubernetes 叢集

1. **使用者提交 K8s 叢集建置請求**：包含 Kubernetes 版本、所需的主控制 (control-plane) 節點數、工作 (worker) 節點數等。  
2. **系統自動調度**：針對每個節點需求，依照指定租戶的配額、群組可用量來尋找合適的 `Baremetal` 建立對應的 `VirtualMachine`。  
3. **外掛與 Service Mesh 選擇**：若在建置流程中勾選需要特定外掛 (Plugin) 或 Service Mesh，系統會在 `K8sClusterPlugin` 與 `K8sClusterToServiceMesh` 中增加紀錄。  
4. **部署完成**：K8s 叢集建立完成後，系統標註相關 VM 與叢集關聯；若指定了堡壘機（Bastion VM），則在 `BastionClusterAssociation` 進行關聯紀錄，以利後續維運。

---

## 6. 系統整體架構

1. **前端 / API 介面**  
   - 以 Django Ninja 或其他 API 框架提供 RESTful 介面，供使用者/管理員進行各類查詢與操作。

2. **核心調度邏輯**  
   - 接收建立虛擬機 / 叢集請求後，負責檢查配額與資源，並挑選合適的實體機 (或群組)。

3. **資料存儲與管理**  
   - 所有資源、租戶、維護者與配額等資訊都存放於資料庫；**詳細的資料表結構與設計已在其他文件中定義**。

4. **外部 Provision Agent**  
   - 系統不直接建立虛擬機或佈署叢集，而是將排程後的結果傳遞給獨立的 Provision Agent，藉此執行實際的建置任務。

---

## 7. 系統特色與未來發展

1. **多型態資源管理**：  
   - 利用多型關聯 (Polymorphic Association) 讓「任何資源」都能被指派給個人或群組維護者，支援組織規模化維運。

2. **跨資料中心支持**：  
   - `Rack` 與 `BaremetalGroup` 的概念使得系統具備跨區域、跨機櫃的資源管理能力，可擴充到更多地理分布的環境。

3. **K8s 擴充能力**：  
   - 透過 `K8sClusterPlugin`、`ServiceMesh` 等機制，未來可支援更多 K8s 生態系插件；也能管理多個網路外掛、監控外掛，甚至不同廠商的 Service Mesh。

4. **租戶與資源彈性**：  
   - 可在運行期間任意調整配額、動態增加或減少租戶、群組，並且保證配額與可用資源同步更新。

5. **集中化維運入口**：  
   - 無論要管理實體機、虛擬機、K8s 叢集，或其外掛、Service Mesh，都能從同一套系統的介面完成查詢、設定與排障。

> **未來可能的擴充**：
> - 加入自動水平擴縮 (Auto Scaling) 功能，根據資源監控指標自動增減虛擬機或工作節點。
> - 與 CI/CD Pipeline 整合，提供更順暢的應用部署體驗。

---

## 8. 小結

此系統整合了「實體機 / 虛擬機管理」、「多租戶與資源配額」、「維護者責任劃分」、「Kubernetes 叢集與附加功能」等多項核心能力，形成一個可於企業內部落地、可擴充的雲端資源調度平台。2.0.0 版本相較於舊版，新增了更多關於維護者 (Maintainer / MaintainerGroup)、K8s 叢集及外掛管理的功能，使系統能更完整地覆蓋從底層硬體到上層容器編排的整體管理流程。

> **注意**：本文件著重在功能規格層面，**詳細資料表設計 (Schema) 請參考獨立的資料庫設計文件 (v2.0.0)**。如需實際欄位與關聯的技術細節，請參閱該文件。
