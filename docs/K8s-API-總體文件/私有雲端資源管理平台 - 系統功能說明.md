# 私有雲端資源管理平台 - 系統功能說明

**適用對象：** 部門管理者、平台操作者、運維團隊

---

## 🌐 系統定位

本平台為企業內部建置的私有雲資源管理系統，由基礎設施維運團隊負責操作與維護，整合虛擬機部署、實體主機配置、Kubernetes 叢集建立、資源配額控管、維護者制度與租戶分層管理等功能。

本系統並非提供給最終使用者操作，而是透過維運人員操作完成後交付結果，確保：

- 各單位資源可見且負責清晰。
- 建立標準流程並落實責任制。
- 平台具備進階調度能力與彈性部署機制。

## 🏗️ 高階架構總覽
我們的系統負責資源管理層，但不負責資源的創建，創建會交由控制器負責。
```text
┌──────────┐
│  Portal  │───╮  (GUI / CLI / API )
└──────────┘   │
      │        │
      ▼        │
┌─────────────────────── 資源管理層（Resource Management） ───────────────────────┐
│ BM 管理 │ VM 管理 │ K8s 管理 │ 租戶與配額 │ 主機群組 │ 維護者 │ 記錄與日誌 │
└────────────────────────────────────────────────────────────────────────────┘
                               │
                               ▼
┌───────────────────────── 外部控制器整合層 ─────────────────────────┐
│ VM Provision Controller │ Bare-metal Controller │ IPAM │ Network Controller │ Storage Controller │
└────────────────────────────────────────────────────────────────────┘
                               │
                               ▼
┌─────────────────────── 基礎設施層（Data Center Layer） ───────────────────────┐
│ 機房/機櫃 │ BMC │ Switch │ Ceph │ NFS │ SAN │ GPU │
└────────────────────────────────────────────────────────────────────────────┘
```
---



# 系統功能規格文件 (v2)

**版本：** 2.0.0
**更新日期：** 2025-03-15

## 1. 簡介

本系統是一套內部專用的資源調度與管理平台，提供下列能力：
1. **資源管理**：管理實體機（Baremetal）、虛擬機（VirtualMachine）、Kubernetes 叢集（K8sCluster）及相關網路與周邊資源。
2. **維護管理**：可指派「個人維護者 (Maintainer)」或「維護者群組 (MaintainerGroup)」負責管理各種資源，並掌握資源所有者或維護者。
3. **多維度分組**：支援「機架 (Rack)」與「實體機群組 (BaremetalGroup)」的概念，可依據地理位置、負載狀況等不同條件，將實體機進行彈性分組。
4. **租戶與配額**：可為不同租戶 (Tenant) 設定在某一資源群組內的配額限制（CPU、記憶體、儲存空間等）。
5. **K8s 叢集管理**：提供 Kubernetes 叢集的建立與管理，包括外掛 (Plugins)、Service Mesh、與堡壘機 (Bastion) 之關聯設定。
6. **自動化調度**：在建立虛擬機或叢集資源時，系統會根據租戶配額、群組可用量、實體機可用量等進行自動化調度與分配。
---

## 2. 系統定位與目標

1. **資源維運可視化**：提供對實體機、虛擬機、K8s 叢集等資源的即時掌握，包括其狀態、位置、已用/可用容量等。
2. **角色分工清晰**：可為每個資源指派個人或群組維護者，以利維運責任劃分與後續稽核。
3. **多租戶環境**：支援將整個資料中心切分給不同組織/部門 (Tenant) 使用，各租戶有可獨立控管的資源配額。
4. **自動化調度機制**：依據資源剩餘量、群組負載、租戶配額等條件，挑選出最適合的實體機或群組，以快速響應建立虛擬機 / 叢集的需求。
5. **K8s 全貌管理**：提供 Kubernetes 叢集層級的監控、外掛管理、堡壘機串接與 Service Mesh 管理等功能。
6. **彈性擴充**：可藉由外掛與多型態關聯 (Polymorphic Association) 機制，拓展系統支持的資源或功能模組。

## 4. 自動化資源調度

### 4.1 調度目標

- **租戶配額檢查**：當要建立虛擬機或 K8s 叢集時，先檢查對應租戶在指定群組的配額。
- **群組可用資源**：檢查該群組內所有實體機的可用 CPU、記憶體及儲存空間等，找出符合需求且負載最適合的實體機。
- **地理或機櫃條件**（選用）：可以在調度演算法中納入 `Rack`、`region`、`dc` 等屬性，執行更精細的調度。

### 4.2 調度流程

1. **收到建立/擴增需求**  
   - 使用者透過 API 提出建立虛擬機 (VM) 或 K8s 叢集的請求，需指定：
     - 租戶 (Tenant)  
     - 目標群組 (BaremetalGroup)  
     - VM 規格 (若為單純建立 VM) 或叢集版本/外掛 (若為建立 K8s 叢集)  
2. **檢查配額與資源**  
   - 由系統查詢 `BaremetalGroupTenantQuota`，判斷租戶在該群組是否還有足夠配額。  
   - 進一步檢索此群組下所有 `Baremetal` 狀態，篩選出可容納需求規格的實體機清單。  
3. **選擇最適合實體機**  
   - 系統可實作多種策略（例如最小剩餘空間優先、或最大剩餘空間優先等）來找出最合適的 Baremetal。  
4. **分配與建立**  
   - 若找到合適的實體機，系統在資料庫中建立對應的 `VirtualMachine` 或更新對應的 `K8sCluster` 紀錄，並透過外部的 Provision Agent/工具實際執行部署。  
   - 資源使用量同時更新（該實體機與該群組的 available_cpu / memory / storage 皆扣減）。  
5. **回報結果**  
   - 若部署成功，系統回傳成功訊息並更新狀態為 `active`；若調度失敗（無可用資源），系統回報錯誤，提示使用者更換群組或調整需求。

## 7. 系統特色與未來發展

1. **多型態資源管理**：  
   - 利用多型關聯 (Polymorphic Association) 讓「任何資源」都能被指派給個人或群組維護者，支援組織規模化維運。

2. **跨資料中心支持**：  
   - `Rack` 與 `BaremetalGroup` 的概念使得系統具備跨區域、跨機櫃的資源管理能力，可擴充到更多地理分布的環境。

3. **K8s 擴充能力**：  
   - 透過 `K8sClusterPlugin`、`ServiceMesh` 等機制，未來可支援更多 K8s 生態系插件；也能管理多個網路外掛、監控外掛，甚至不同廠商的 Service Mesh。

4. **租戶與資源彈性**：  
   - 可在運行期間任意調整配額、動態增加或減少租戶、群組，並且保證配額與可用資源同步更新。

5. **集中化維運入口**：  
   - 無論要管理實體機、虛擬機、K8s 叢集，或其外掛、Service Mesh，都能從同一套系統的介面完成查詢、設定與排障。

> **未來可能的擴充**：
> - 加入自動水平擴縮 (Auto Scaling) 功能，根據資源監控指標自動增減虛擬機或工作節點。
> - 與 CI/CD Pipeline 整合，提供更順暢的應用部署體驗。
