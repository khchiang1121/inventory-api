# **實體機分組策略與考量**

**版本：** 1.0.0
**更新日期：** 2025-03-19

## **1. 簡介**
在雲端架構中，我們希望能夠對 **實體機 (Baremetal)** 進行分組，以利於資源管理與調度。同時，**虛擬機 (Virtual Machine, VM)** 需要選擇適當的 **群組 (Group)** 來確保資源的最佳化配置。

在初期設想中，`Cluster` 與 `Group` 採取 **1:1** 的對應關係，即一個 `Group` 對應一個 `Cluster`，例如：

| Group   | Cluster  |
|---------|----------|
| group1  | cluster1 |
| group2  | cluster2 |
| group3  | cluster3 |

然而，隨著需求擴展，我們需要允許 **一台實體機可以服務於多個 Cluster**，主要有以下 3 種可能的分組方式：

1. **允許一台實體機屬於多個 Group**
2. **允許不同的 Cluster 指定相同的 Group**
3. **允許一個 Cluster 指定多個 Group**

這三種方案各有其適用場景與挑戰，以下將分別探討。

## **2. 多群組 vs 單群組的影響**
### **2.1 讓實體機同時屬於多個群組**
此設計允許一台實體機歸屬於多個 `Group`，例如：

| Group  | Baremetal (BM) |
|--------|----------------|
| group1 | bm1            |
| group2 | bm1            |
| group3 | bm1            |

#### **優勢**
- **提高資源利用率**：不同 `Cluster` 可以共享相同的物理機資源，提高使用率。
- **提升靈活性**：允許 `Group` 代表不同的業務單元，讓共享資源的 `Cluster` 能夠根據需求動態調度。

#### **挑戰**
- **資源衝突風險**：當同一台實體機同時屬於多個群組時，不同群組內的資源調度策略可能會產生衝突，例如：
  - `Group A` 允許超額配置，而 `Group B` 嚴格限制資源，可能導致 `Group A` 影響 `Group B` 的服務。
  - 調度邏輯複雜化，需額外處理 **預留資源** 與 **實際資源使用率** 之間的關係。
- **管理與監控成本提升**：  
  - 需要額外的監控與調度機制，確保不會因為跨群組使用而導致某些 `Group` 過度消耗資源。

#### 小結
- 只有當業務場景有非常明確的需求（例如同時兼具不同的業務、或需要特殊資源共享）時，才會允許一台主機屬於多個群組。
- 即使允許這種作法，通常也會伴隨非常精細的資源管理策略，以避免出現資源競爭、資源超額分配或調度不明確的問題。
> **結論**：  
業界普遍不建議讓一台實體機同時歸屬於多個 `Group`，因為這會導致調度、監控與資源管理的複雜性大幅提升。

### **2.2 允許不同的 Cluster 指定相同的 Group**
另一種方式是讓不同 `Cluster` 指定相同的 `Group`，例如：

| Cluster  | Group  | Baremetal (BM) |
|----------|--------| -------- |
| cluster1 | group1 | bm1-1 |
| cluster2 | group1 | bm2-1 |
| cluster3 | group1 | bm3-1 |

#### **優勢**
- **簡化管理**：相同的 `Group` 可以共享資源與策略，降低維運成本。
- **提高彈性**：多個 `Cluster` 可以使用相同的 `Group` 來分配資源，使得某些低負載 `Cluster` 能夠借用資源。

#### **挑戰**
- **責任不明確**：  
  - 若 `Group1` 同時服務 `Cluster1` 和 `Cluster2`，則 `Group1` 的管理責任需要額外界定，例如誰負責資源調度與維運。
- **調度策略可能衝突**：  
  - `Cluster1` 可能使用高可用性 (HA) 調度，而 `Cluster2` 可能使用最佳效能 (Best Performance) 調度，若 `Group1` 內的 `BM` 被不同策略同時調度，可能導致資源競爭。

#### **允許多 `Cluster` 共享 `Group` 的情境**
若系統有特殊需求，需允許多個 `Cluster` 指定相同的 `Group`，則應滿足以下條件：
- **確保資源隔離機制**：  
  - 需額外開發資源預留與隔離策略，例如：
    - `Cluster1` 只能使用 `Group1` 內 **30%** 的資源。
    - `Cluster2` 則只能使用 `Group1` 內 **70%** 的資源。
- **明確指定管理責任人**：  
  - 若 `Group` 被多個 `Cluster` 共享，則應明確指定負責該 `Group` 的管理者，以確保運維責任不會模糊。
- **動態調度與監控**：
  - 需建立即時監控機制，確保 `Cluster1` 與 `Cluster2` 不會同時調用超過 `Group1` 允許的總資源。
 
> **結論**：  
**允許不同的 Cluster 指定相同的 Group 是合理的做法**，但需要搭配適當的 **資源隔離與調度策略** 來管理不同 `Cluster` 之間的競爭與分配。

### **2.3 允許一個 Cluster 指定多個 Group**
此設計允許 **一個 `Cluster` 調度來自多個 `Group` 的資源**，例如：

| Cluster  | Group  | Baremetal (BM) |
|----------|--------|--------|
| cluster1 | group1 | bm1-1  |
| cluster1 | group2 | bm2-1  |
| cluster1 | group3 | bm3-1  |

#### **優勢**
- **擴展性高**：`Cluster` 可以從多個 `Group` 調度資源，讓 Kubernetes 可以更靈活地選擇可用的 `BM` 來分配 `VM`。
- **適合異質環境**：當 `Group` 代表不同類型的硬體（如 GPU 伺服器 vs CPU 伺服器），則 `Cluster` 可以根據 `VM` 的需求選擇適當的 `Group` 來調度。

##### **挑戰**
- **調度邏輯需更精細**：
  - `Cluster` 需要確保 `VM` 會被正確地分配到適合的 `Group`，而不會出現資源錯誤使用的情況。
- **租戶概念可能消失**：
  - 此方式實際上將 `Cluster` 視為 `Tenant`，若 `VM` 並非僅供 `Cluster` 使用，而是應屬於 `Tenant`，那麼 `VM` 該如何選擇 `Group`？是否需要獨立的調度機制？

> **結論**：允許 **1 個 Cluster 指定多個 Group** 是合理的設計，但應搭配 **標籤 (Labeling)** 與 **資源調度機制** 來確保資源能夠被適當分配。此外，若 `VM` 並非僅供 `Cluster` 使用，而是直接屬於 `Tenant`，則需明確 `Tenant` 的角色，避免調度邏輯混亂。

## **3. `Tenant`、`Cluster`、`Group` 之間的關係**
### **差異與適用場景**
| 設計方式 | 描述 | 適用場景 | 挑戰 |
|----------|------|---------|------|
| **允許 1 個 Cluster 指定多個 Group** | Cluster 可選擇來自多個 Group 的資源 | 異質硬體環境 (CPU/GPU)、動態資源池 | 需有效的資源調度 |
| **允許多個 Cluster 指定相同的 Group** | 多個 Cluster 可使用相同的 Group 內的 BM | 跨 Cluster 共享資源 (如 HPC) | 需明確資源管理與責任歸屬 |
| **允許一台 BM 同時屬於多個 Group** | BM 可同時屬於多個 Group | 共享基礎設施 (不建議) | 監控與調度過於複雜 |

> **結論**：  
- **租戶 (Tenant) 是邏輯概念**，代表業務單位或使用者組織，可擁有多個 `Cluster` 或 `Group`。  
- **Cluster 負責調度 VM**，可以從一個或多個 `Group` 取得資源。  
- **Group 是物理資源池**，代表一組 `BM`，可供一個或多個 `Cluster` 使用。


### **4. Group Quota 設計**
當 `Group` 具備共享概念時，需要機制來設定各使用者的 **資源配額 (Quota)**，以確保公平分配。

由於 **一台實體機只能屬於一個 `Group`**，如果 `Group` 需要被多個 `Tenant` 共享，則相當於將原本的獨立 `Group` **合併** 為一個共用群組。因此，我們需要透過 Quota 來管理租戶的資源佔比，例如：

- `Tenant A` 只能使用 `Group` 內 **40%** 的資源  
- `Tenant B` 則可使用 **60%** 的資源  

這樣的設計確保了每個租戶在共享 `Group` 時仍能獲得明確的資源保障，避免因競爭導致資源爭奪或不公平分配。

## **推薦的解決方案：使用「共用群組」+「租戶標記」設計**
當需要讓多個租戶共享同一組實體機時，應採用以下架構：

- **一台實體機只能屬於一個 `Group`**，這是資源管理的基礎單位。
- **一個 `Group` 可以同時提供給多個 `Tenant` 使用**，但需透過 **配額 (Quota) 機制** 限制租戶的資源使用量。
- **一個 `Tenant` 可以使用多個 `Group` 的資源**，以提高靈活性和可用性。
- **VM 建立時須同時指定「租戶 (Tenant)」與「群組 (Group)」**，確保：
  - 系統能夠依據 `Tenant` 的 **可用配額** 和 **群組內的剩餘資源** 進行分配。
  - 若 `Group` 內的資源不足，調度機制應返回錯誤，讓 `Tenant` 重新選擇 `Group` 或調整需求。

這樣的設計避免了一台實體機同時屬於多個 `Group` 的複雜性，並確保租戶之間的資源隔離性。



### **推薦架構**

```
Tenant A, Tenant B (租戶)
          |
          |  申請資源
          |
Baremetal Group 1, Baremetal Group 2 (實體機群組)
          |
          |  管理實體機
          |
Baremetal 01, Baremetal 02, Baremetal 03 ... (實體機)
```

- **`Group` (群組)**：實體機的管理單位，根據地理位置、伺服器類型或業務用途進行分類。
- **`Tenant` (租戶)**：代表不同的業務單位或用戶群組，透過 `Quota` 限制其可用資源。
- **`VM` (虛擬機)**：由 `Tenant` 建立並運行於 `Group` 內的 `Baremetal` 上，受配額管理。

---

## **實務案例說明**

### **範例**
假設 **Tenant A** 和 **Tenant B** 共享 **10 台實體機**，我們可以採用 **共用 `Group` + Quota 機制** 來管理資源：

1. **共用 `Group` 設定**
   - 這 10 台實體機被劃分到一個共享的 `Group`，供 `Tenant A` 和 `Tenant B` 使用。
   
2. **租戶資源配額**
   - `Tenant A` 只能使用 **40%** 的 `Group` 資源。
   - `Tenant B` 則可使用 **60%** 的 `Group` 資源。

3. **VM 調度流程**
   - `Tenant A` 請求建立 `VM`，系統檢查 `Group` 內的可用資源及租戶的剩餘 `Quota`。
   - 如果 `Quota` 允許，系統根據調度策略選擇合適的 `Baremetal` 來運行 `VM`。
   - 若 `Quota` 或 `Group` 內的資源不足，則返回錯誤，要求租戶重新選擇 `Group` 或調整需求。


---

### **優勢**
- **資源管理簡單清晰**：每台 `Baremetal` 只屬於一個 `Group`，避免多群組歸屬帶來的管理困難。
- **租戶之間資源獨立**：透過 `Quota` 確保不同租戶之間的公平資源分配，避免競爭影響。
- **靈活的擴展性**：`Tenant` 可以同時存取多個 `Group`，適應不同應用場景。

---

## **結論與建議**
綜合考量 **資源管理、調度靈活性及租戶隔離性**，最佳實踐應遵循以下原則：
- **每台 `Baremetal` 只屬於一個 `Group`**，但該 `Group` 可供多個 `Tenant` 共享。
- **`Tenant` 的資源使用應透過 `Quota` 控制**，確保公平性和隔離性。
- **`Cluster` 調度應依據 `Group` 內的可用資源與 `Tenant` 的 `Quota`**，避免資源衝突。

這種設計能夠最大化資源利用率，同時確保系統穩定性與管理的簡單性。
